//
//  ChatViewModel.swift
//  AIPaperReader
//
//  Created by Claude on 2/4/26.
//

import SwiftUI
import SwiftData
import PDFKit
import Combine

enum PageRangeOption: String, CaseIterable {
    case all = "Full Document"
    case currentPage = "Current Page"
    case custom = "Custom Range"

    var displayName: String {
        switch self {
        case .all: return "å…¨æ–‡"
        case .currentPage: return "å½“å‰é¡µ"
        case .custom: return "è‡ªå®šä¹‰èŒƒå›´"
        }
    }
}

/// é¢„è®¾é—®é¢˜ç»“æ„
struct PresetQuestion: Identifiable, Codable, Equatable {
    var id: UUID = UUID()
    var english: String
    var chinese: String
    var icon: String = "arrow.right.circle"
    var isBuiltIn: Bool = true

    static func custom(chinese: String) -> PresetQuestion {
        PresetQuestion(english: chinese, chinese: chinese, icon: "star.fill", isBuiltIn: false)
    }
}

@MainActor
class ChatViewModel: ObservableObject {
    // MARK: - Published Properties

    @Published var messages: [ChatMessage] = [] {
        didSet {
           // Autosave logic could go here, but doing it explicitly is safer
        }
    }
    @Published var inputText: String = ""
    @Published var isGenerating: Bool = false
    @Published var currentStreamingText: String = ""
    @Published var errorMessage: String?

    @Published var pageRangeOption: PageRangeOption = .all
    @Published var customPageRange: String = ""
    @Published var estimatedTokens: Int = 0
    @Published var ingestionProgress: Double = 0.0
    @Published var isIngesting: Bool = false
    @Published var currentSelection: String?
    @Published var isSearchingContext: Bool = false

    // MARK: - Private Properties

    private var llmService: LLMServiceProtocol?
    private let textExtractor = PDFTextExtractor()
    private let contextManager = ContextManager()
    private var currentTask: Task<Void, Never>?
    private let settings = AppSettings.shared
    
    // Persistence
    var modelContext: ModelContext?
    var currentSession: ChatSession?

    // MARK: - Preset Questions (ä¸­è‹±åŒè¯­)

    static let builtInQuestions: [PresetQuestion] = [
        PresetQuestion(
            english: "Summarize the main contributions of this paper",
            chinese: "æ€»ç»“è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®",
            icon: "star.fill"
        ),
        PresetQuestion(
            english: "What is the research methodology used?",
            chinese: "è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†ä»€ä¹ˆç ”ç©¶æ–¹æ³•ï¼Ÿ",
            icon: "testtube.2"
        ),
        PresetQuestion(
            english: "List the main conclusions",
            chinese: "åˆ—å‡ºä¸»è¦ç»“è®º",
            icon: "checkmark.seal.fill"
        ),
        PresetQuestion(
            english: "What are the limitations of this study?",
            chinese: "è¿™é¡¹ç ”ç©¶æœ‰å“ªäº›å±€é™æ€§ï¼Ÿ",
            icon: "exclamationmark.triangle.fill"
        ),
        PresetQuestion(
            english: "Explain the key findings",
            chinese: "è§£é‡Šä¸»è¦å‘ç°",
            icon: "lightbulb.fill"
        ),
        PresetQuestion(
            english: "How is the introduction written? What writing tips can I learn?",
            chinese: "Introduction æ˜¯å¦‚ä½•è¡Œæ–‡çš„ï¼Ÿæˆ‘å¯ä»¥å­¦åˆ°å“ªäº›å†™ä½œæŠ€å·§ï¼Ÿ",
            icon: "pencil.and.outline"
        )
    ]

    /// è·å–æ‰€æœ‰é¢„è®¾é—®é¢˜ï¼ˆä»…å†…ç½®é—®é¢˜ï¼Œè‡ªå®šä¹‰æ“ä½œç°åœ¨æ˜¯ç‹¬ç«‹çš„ CustomQuickActionï¼‰
    static var allPresetQuestions: [PresetQuestion] {
        return builtInQuestions
    }

    /// æ—§ç‰ˆå…¼å®¹ï¼šåªè¿”å›è‹±æ–‡é—®é¢˜
    static var presetQuestions: [String] {
        builtInQuestions.map { $0.english }
    }

    private var cancellables = Set<AnyCancellable>()

    init() {
        updateLLMService()
        
        // bind context manager progress
        contextManager.$ingestionProgress
            .receive(on: RunLoop.main)
            .assign(to: \.ingestionProgress, on: self)
            .store(in: &cancellables)
            
        contextManager.$isIngesting
            .receive(on: RunLoop.main)
            .assign(to: \.isIngesting, on: self)
            .store(in: &cancellables)
    }
    
    func setModelContext(_ context: ModelContext) {
        self.modelContext = context
    }
    
    func loadSession(for documentId: String) {
        guard let context = modelContext else { return }
        
        let descriptor = FetchDescriptor<ChatSession>(
            predicate: #Predicate { $0.documentId == documentId },
            sortBy: [SortDescriptor(\.createdAt, order: .reverse)]
        )
        
        do {
            if let existingSession = try context.fetch(descriptor).first {
                self.currentSession = existingSession
                // Sort messages by timestamp
                let sortedMessages = existingSession.messages.sorted { $0.timestamp < $1.timestamp }
                self.messages = sortedMessages.map { model in
                    if model.role == .user {
                        return ChatMessage.user(model.content)
                    } else {
                        return ChatMessage.assistant(model.content)
                    }
                }
            } else {
                // Create new session
                let newSession = ChatSession(documentId: documentId)
                context.insert(newSession)
                self.currentSession = newSession
                self.messages = []
            }
        } catch {
            print("Failed to load session: \(error)")
        }
    }
    
    func saveMessage(_ message: ChatMessage) {
        guard let context = modelContext, let session = currentSession else { return }
        
        // Convert UI model to SwiftData model
        let msgModel = ChatMessageModel(
            role: message.role,
            content: message.content
        )
        msgModel.session = session // Set relationship (assuming optional or set 'messages' array)
        session.messages.append(msgModel) // Add to relationship
        
        do {
            try context.save()
        } catch {
            print("Failed to save message: \(error)")
        }
    }

    func updateLLMService() {
        let config = settings.llmConfig
        llmService = LLMServiceFactory.create(config: config)
    }

    func ingestDocument(_ document: PDFDocument) {
        Task {
            await contextManager.ingest(document: document)
        }
    }

    // MARK: - Public Methods

    func sendMessage(document: PDFDocument?, currentPageIndex: Int) {
        guard !inputText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty else { return }
        guard let document = document else {
            errorMessage = "Please open a PDF document first"
            return
        }

        let userMessageContent = inputText
        inputText = ""

        // Add user message
        let userMessage = ChatMessage.user(userMessageContent)
        messages.append(userMessage)
        saveMessage(userMessage)

        // Start generating
        isGenerating = true
        currentStreamingText = ""
        errorMessage = nil

        currentTask = Task {
            do {
                // Extract PDF content based on page range
                await MainActor.run { self.isSearchingContext = true }
                let pdfContent = await extractPDFContent(from: document, currentPageIndex: currentPageIndex, query: userMessageContent)
                await MainActor.run { self.isSearchingContext = false }

                // Build system prompt
                let systemPrompt = buildSystemPrompt(pdfContent: pdfContent)

                // Update LLM service with latest config
                updateLLMService()

                guard let service = llmService else {
                    throw LLMError.connectionFailed
                }

                // Send to LLM
                try await service.sendMessage(
                    messages: messages,
                    systemPrompt: systemPrompt,
                    onToken: { [weak self] token in
                        self?.currentStreamingText += token
                    },
                    onComplete: { [weak self] in
                        self?.finalizeResponse()
                    },
                    onError: { [weak self] error in
                        self?.handleError(error)
                    }
                )
            } catch {
                handleError(error)
            }
        }
    }

    func sendPresetQuestion(_ question: String, document: PDFDocument?, currentPageIndex: Int) {
        inputText = question
        sendMessage(document: document, currentPageIndex: currentPageIndex)
    }

    func stopGenerating() {
        currentTask?.cancel()
        llmService?.cancel()
        finalizeResponse()
    }

    func clearChat() {
        messages.removeAll()
        currentStreamingText = ""
        errorMessage = nil
        contextManager.clear()
        currentSession = nil
    }

    /// å¼€å§‹æ–°çš„èŠå¤©ä¼šè¯ï¼ˆä¿ç•™æ—§çš„å†å²ï¼‰
    func startNewChat(for documentId: String) {
        guard let context = modelContext else { return }

        // åˆ›å»ºæ–°çš„ä¼šè¯
        let newSession = ChatSession(documentId: documentId, title: "New Chat \(Date().formatted(date: .abbreviated, time: .shortened))")
        context.insert(newSession)
        self.currentSession = newSession
        self.messages = []

        do {
            try context.save()
        } catch {
            print("Failed to create new session: \(error)")
        }
    }

    /// åˆ é™¤æŒ‡å®šçš„èŠå¤©ä¼šè¯
    func deleteSession(_ session: ChatSession) {
        guard let context = modelContext else { return }

        // å¦‚æœåˆ é™¤çš„æ˜¯å½“å‰ä¼šè¯ï¼Œæ¸…ç©ºå½“å‰èŠå¤©
        if session.id == currentSession?.id {
            messages.removeAll()
            currentSession = nil
        }

        context.delete(session)

        do {
            try context.save()
        } catch {
            print("Failed to delete session: \(error)")
        }
    }

    /// è·å–å½“å‰æ–‡æ¡£çš„æ‰€æœ‰å†å²ä¼šè¯
    func fetchSessions(for documentId: String) -> [ChatSession] {
        guard let context = modelContext else { return [] }

        let descriptor = FetchDescriptor<ChatSession>(
            predicate: #Predicate { $0.documentId == documentId },
            sortBy: [SortDescriptor(\.createdAt, order: .reverse)]
        )

        do {
            return try context.fetch(descriptor)
        } catch {
            print("Failed to fetch sessions: \(error)")
            return []
        }
    }

    /// åˆ‡æ¢åˆ°æŒ‡å®šçš„ä¼šè¯
    func switchToSession(_ session: ChatSession) {
        self.currentSession = session
        // æŒ‰æ—¶é—´æ’åºæ¶ˆæ¯
        let sortedMessages = session.messages.sorted { $0.timestamp < $1.timestamp }
        self.messages = sortedMessages.map { model in
            if model.role == .user {
                return ChatMessage.user(model.content)
            } else {
                return ChatMessage.assistant(model.content)
            }
        }
    }

    // MARK: - Chat Export

    /// å°†å½“å‰èŠå¤©å¯¼å‡ºä¸º Markdown æ ¼å¼
    func exportChatAsMarkdown() -> String {
        var md = "# èŠå¤©è®°å½•\n\n"
        if let session = currentSession {
            md += "- æ–‡æ¡£: \(session.documentId)\n"
            md += "- æ—¥æœŸ: \(Date().formatted(date: .long, time: .shortened))\n\n"
        }
        md += "---\n\n"

        for message in messages {
            switch message.role {
            case .user:
                md += "## ğŸ§‘ ç”¨æˆ·\n\n\(message.content)\n\n---\n\n"
            case .assistant:
                md += "## ğŸ¤– AI åŠ©æ‰‹\n\n\(message.content)\n\n---\n\n"
            case .system:
                break
            }
        }
        return md
    }

    /// å¯¼å‡ºèŠå¤©è®°å½•åˆ°æ–‡ä»¶
    func exportChatToFile() {
        guard !messages.isEmpty else { return }
        let markdown = exportChatAsMarkdown()
        let panel = NSSavePanel()
        panel.allowedContentTypes = [.plainText]
        panel.nameFieldStringValue = "chat-export-\(Date().formatted(date: .numeric, time: .omitted)).md"
        panel.begin { response in
            guard response == .OK, let url = panel.url else { return }
            try? markdown.write(to: url, atomically: true, encoding: .utf8)
        }
    }

    func updateTokenEstimate(document: PDFDocument?, currentPageIndex: Int) {
        guard let document = document else {
            estimatedTokens = 0
            return
        }

        Task {
            let content = await extractPDFContent(from: document, currentPageIndex: currentPageIndex, query: "")

            await MainActor.run {
                // è®¡ç®— PDF å†…å®¹çš„ token
                let contentTokens = textExtractor.estimateTokenCount(content)

                // è®¡ç®— system prompt çš„ tokenï¼ˆä¸åŒ…å« PDF å†…å®¹å ä½ç¬¦ï¼‰
                let systemPromptBase = settings.systemPrompt.replacingOccurrences(of: "{pdf_content}", with: "")
                let systemPromptTokens = textExtractor.estimateTokenCount(systemPromptBase)

                // è®¡ç®—å†å²å¯¹è¯çš„ token
                let historyTokens = messages.reduce(0) { total, message in
                    total + textExtractor.estimateTokenCount(message.content)
                }

                // æ€»è®¡
                estimatedTokens = contentTokens + systemPromptTokens + historyTokens
            }
        }
    }

    // MARK: - Private Methods

    private func extractPDFContent(from document: PDFDocument, currentPageIndex: Int, query: String) async -> String {
        // æ•è·é€‰ä¸­çš„æ–‡æœ¬ï¼ˆç”¨å®Œåæ¸…ç©ºï¼‰
        let selectionText = currentSelection

        switch pageRangeOption {
        case .all:
            // Try RAG first if we have context
            if !query.isEmpty {
                // Smart Context: If text is selected, prioritize it!
                if let selection = selectionText, !selection.isEmpty {
                    print("Using Smart Context (Selection)")
                    // æ¸…ç©ºé€‰æ‹©ï¼Œé¿å…åç»­æé—®ä»ç„¶ä½¿ç”¨
                    await MainActor.run { self.currentSelection = nil }
                    return "--- User Selected Text (High Priority) ---\n\(selection)\n\n--- Document Context ---\n" + textExtractor.extractTextWithBudget(from: document, tokenBudget: settings.llmContextTokenBudget / 2).text
                }

                let relevantChunks = await contextManager.retrieve(query: query)
                if !relevantChunks.isEmpty {
                    print("Using RAG: Found \(relevantChunks.count) relevant chunks")
                    return relevantChunks.map { "--- Page \($0.pageRange.lowerBound + 1)-\($0.pageRange.upperBound) ---\n\($0.text)" }.joined(separator: "\n\n")
                }
            }

            // Fallback to token budget extraction (e.g. for summarization or no matches)
            let result = textExtractor.extractTextWithBudget(
                from: document,
                tokenBudget: settings.llmContextTokenBudget
            )
            return result.text

        case .currentPage:
            let result = textExtractor.extractText(
                from: document,
                pages: currentPageIndex..<(currentPageIndex + 1)
            )
            return result.text

        case .custom:
            if let result = textExtractor.extractText(from: document, rangeString: customPageRange) {
                return result.text
            }
            // Fall back to current page if custom range is invalid
            let result = textExtractor.extractText(
                from: document,
                pages: currentPageIndex..<(currentPageIndex + 1)
            )
            return result.text
        }
    }

    private func buildSystemPrompt(pdfContent: String) -> String {
        var prompt = settings.systemPrompt

        // Replace placeholder with actual content
        prompt = prompt.replacingOccurrences(of: "{pdf_content}", with: pdfContent)

        return prompt
    }

    private func finalizeResponse() {
        if !currentStreamingText.isEmpty {
            let assistantMessage = ChatMessage.assistant(currentStreamingText)
            messages.append(assistantMessage)
            saveMessage(assistantMessage)
        }
        currentStreamingText = ""
        isGenerating = false
    }

    private func handleError(_ error: Error) {
        isGenerating = false

        if let llmError = error as? LLMError {
            switch llmError {
            case .cancelled:
                // Don't show error for cancellation
                return
            default:
                errorMessage = llmError.localizedDescription
            }
        } else {
            errorMessage = error.localizedDescription
        }

        // Add error message to chat if there was streaming content
        if !currentStreamingText.isEmpty {
            currentStreamingText += "\n\n[Error: \(errorMessage ?? "Unknown error")]"
            finalizeResponse()
        }
    }
}
